# -*- coding: utf-8 -*-
"""
ç§‘åˆ›ç ”ä¹ ç¤¾ Â· å¸åœˆèµ„è®¯è‡ªåŠ¨æ¨é€ï¼ˆå°æ—¶å¿«æŠ¥ï¼‰
- æºï¼šBinance å®˜æ–¹ RSS/CMS + å„å¤§ Statuspage + Nitter é•œåƒ RSS + åª’ä½“RSS
- ä¸­æ–‡åŒ–ï¼šæœ¯è¯­æ›¿æ¢ï¼›åˆ†åŒºï¼›ç½®é¡¶å…³é”®è¯ï¼›å»é‡
- æ¨é€ï¼šPushPlusï¼ˆåœ¨ä»“åº“ Secrets é‡Œé…ç½® PUSHPLUS_TOKENï¼‰
"""

import os, re, time, json, datetime, requests, feedparser, urllib.parse

PUSHPLUS_TOKEN = os.environ.get("PUSHPLUS_TOKEN","\").strip()
TIMEOUT = 25
UA = {"User-Agent":"Mozilla/5.0 (GitHubActions) CryptoDigest/1.0"}

# ---------- æ•°æ®æº ----------
NITTERS = [
  "https://nitter.net","https://nitter.poast.org",
  "https://nitter.tiekoetter.com","https://nitter.domain.glass",
  "https://nitter.lacontrevoie.fr",
]
def nitter_feeds(h): return [f"{u.rstrip('/')}/{h}/rss" for u in NITTERS]

EX_RSS = [
  "https://www.binance.com/zh-CN/support/announcement/rss",
  *nitter_feeds("binance"), *nitter_feeds("OKX"),
  *nitter_feeds("Bybit_Official"), *nitter_feeds("krakenfx"),
  *nitter_feeds("coinbase")
]
MEDIA_RSS = [
  "https://www.coindesk.com/arc/outboundfeeds/rss/",
  "https://cointelegraph.com/rss", "https://decrypt.co/feed",
  *nitter_feeds("WuBlockchain")
]
ECO_RSS = [
  *nitter_feeds("arbitrum"), *nitter_feeds("optimismFND"),
  *nitter_feeds("zksync"), *nitter_feeds("solana"),
  *nitter_feeds("0xPolygon"), *nitter_feeds("avax"),
  *nitter_feeds("AptosLabs"), *nitter_feeds("SuiNetwork"),
  *nitter_feeds("ton_blockchain"), *nitter_feeds("BuildOnBase"),
]
STATUSPAGES = [
  ("Binance","https://status.binance.com"),
  ("OKX","https://status.okx.com"),
  ("Bybit","https://status.bybit.com"),
  ("Coinbase","https://status.coinbase.com"),
  ("Kraken","https://status.kraken.com"),
]

# ---------- æŠ“å– ----------
def to_x_link(link:str)->str:
  if not link: return link
  if "nitter" in link:
    u=urllib.parse.urlparse(link); p=u.path.strip("/").split("/")
    if len(p)>=3 and p[1]=="status": return "https://x.com/" + "/".join(p[:3])
  if link.startswith("/"): return "https://x.com"+link
  return link

def fetch_rss(url):
  try:
    r=requests.get(url,headers=UA,timeout=TIMEOUT); r.raise_for_status()
    fp=feedparser.parse(r.content); out=[]
    for e in fp.entries[:40]:
      t=(getattr(e,"title","") or "").strip()
      l=to_x_link((getattr(e,"link","") or "").strip())
      s=(getattr(e,"summary","") or getattr(e,"description","") or "").strip()
      pub=(getattr(e,"published","") or getattr(e,"updated","") or "")
      ts=pub.replace("T"," ").replace("Z","").split("+")[0].strip()
      out.append({"source":url,"title":t,"summary":s,"link":l,"ts":ts})
    return out
  except Exception:
    return []

def fetch_binance_cms(rows=40):
  def parse(j):
    items=[]
    arts=(((j or {}).get("data") or {}).get("articles")) or []
    for a in arts[:rows]:
      title=(a.get("title") or "").strip()
      code=a.get("code") or a.get("id") or ""
      ts_ms=a.get("releaseDate") or a.get("createTime") or 0
      link=f"https://www.binance.com/en/support/announcement/{code}" if code else ""
      try: ts=datetime.datetime.fromtimestamp(ts_ms/1000).strftime("%Y-%m-%d %H:%M")
      except: ts=""
      items.append({"source":"binance_cms","title":title,"summary":"","link":link,"ts":ts})
    return items
  urls=[
    f"https://www.binance.com/bapi/composite/v1/public/cms/article/list/query?type=1&page=1&rows={rows}",
    f"https://www.binance.com/bapi/composite/v1/public/cms/article/list?type=1&page=1&rows={rows}",
  ]
  for u in urls:
    try:
      r=requests.get(u,headers=UA,timeout=TIMEOUT)
      if r.status_code==200:
        it=parse(r.json())
        if it: return it
    except: pass
  return []

def fetch_statuspage(base,name):
  url=base.rstrip("/")+"/api/v2/summary.json"
  try:
    r=requests.get(url,headers=UA,timeout=TIMEOUT); r.raise_for_status()
    j=r.json()
  except: return []
  out=[]
  incidents=(j.get("incidents") or []) + (j.get("scheduled_maintenances") or [])
  for inc in incidents[:20]:
    title=inc.get("name") or ""
    status=inc.get("status") or ""
    seg=[]
    if status: seg.append("çŠ¶æ€ï¼š"+status)
    ups=inc.get("incident_updates") or []
    if ups:
      body=(ups[0].get("body") or "").strip()
      if body: seg.append((body[:180]+"â€¦") if len(body)>180 else body)
    summary=" | ".join(seg)
    link=inc.get("shortlink") or base
    ts=(inc.get("created_at") or "").replace("T"," ").replace("Z","").split("+")[0].strip()
    out.append({"source":"status_"+name.lower(),"title":"["+name+" çŠ¶æ€] "+title,"summary":summary,"link":link,"ts":ts})
  return out

# ---------- ä¸­æ–‡åŒ– & åˆ†åŒº ----------
GLOSSARY=[(r'\bspot\b','ç°è´§'),(r'\bfutures?\b','æœŸè´§'),(r'\bperpetual(s)?\b','æ°¸ç»­'),
          (r'\bmargin\b','æ æ†'),(r'\blist(ed|ing|s)?\b','ä¸Šçº¿'),(r'\blaunch(ing|ed)?\b','ä¸Šçº¿'),
          (r'\bmaintenance\b','ç»´æŠ¤'),(r'\bsuspend(ed|s|ing)?\b','æš‚åœ'),(r'\bresume(d|s|ing)?\b','æ¢å¤'),
          (r'\bdeposit(s)?\b','å……å€¼'),(r'\bwithdraw(al|s|ing)?\b','æç°'),
          (r'\bstaking\b','è´¨æŠ¼'),(r'\bairdrop\b','ç©ºæŠ•'),(r'\btestnet\b','æµ‹è¯•ç½‘'),
          (r'\bmainnet\b','ä¸»ç½‘'),(r'\bsnapshot\b','å¿«ç…§'),(r'\bclaim\b','é¢†å–')]
def zhify(s:str)->str:
  s=s or ""
  for pat,rep in GLOSSARY: s=re.sub(pat,rep,s,flags=re.IGNORECASE)
  return re.sub(r'\s+',' ',s).strip()

KEYS=["æš‚åœ","ç»´æŠ¤","é»‘å®¢","æ¼æ´","ä¸Šçº¿","æ°¸ç»­","æœŸè´§","ç°è´§","ä¸‹æ¶","ç©ºæŠ•","æµ‹è¯•ç½‘","ä¸»ç½‘","å¿«ç…§","é¢†å–"]
def score_hi(t):
  sc=0; out=t
  for kw in KEYS:
    if kw in t: sc+=1; out=out.replace(kw,"**"+kw+"**")
  return sc,("ã€âš é‡ç‚¹ã€‘"+out) if sc>0 else out

def classify(it):
  t=(it["title"]+" "+it["summary"]).lower()
  if any(k in t for k in ["listing","ä¸Šçº¿","launch","maintenance","ç»´æŠ¤","perpetual","æ°¸ç»­","margin","æ æ†","spot","ç°è´§","æœŸè´§","futures","delist","ä¸‹æ¶"]): return "ğŸ”¥ æ–°å¸/è¿è¥"
  if any(k in t for k in ["airdrop","ç©ºæŠ•","æµ‹è¯•ç½‘","testnet","claim","é¢†å–","å¿«ç…§","snapshot","quest"]): return "ğŸ’§ æµ‹è¯•ç½‘/ç©ºæŠ•"
  if any(k in t for k in ["whale","å·¨é²¸","å¤§é¢è½¬è´¦","è½¬å…¥","è½¬å‡º","on-chain","é“¾ä¸Š","inflow","outflow"]): return "ğŸ³ é“¾ä¸Šé²¸é±¼"
  if any(h in (it["source"] or "") for h in ["binance.com","okx.com","bybit.com","kraken.com","coinbase.com","status_","nitter"]): return "ğŸ“£ äº¤æ˜“æ‰€æ›´æ–°"
  if any(k in t for k in ["arbitrum","optimism","zksync","solana","polygon","avax","aptos","sui","ton","base","starknet","sei","celestia","near","cosmos"]): return "ğŸŒ ç”Ÿæ€å™äº‹"
  return "ğŸ¦ åª’ä½“å¤´æ¡"

SECTIONS=[("ğŸ”¥ æ–°å¸/è¿è¥","ğŸ”¥ æ–°å¸/è¿è¥"),("ğŸ’§ æµ‹è¯•ç½‘/ç©ºæŠ•","ğŸ’§ æµ‹è¯•ç½‘/ç©ºæŠ•"),
          ("ğŸ³ é“¾ä¸Šé²¸é±¼","ğŸ³ é“¾ä¸Šé²¸é±¼"),("ğŸ“£ äº¤æ˜“æ‰€æ›´æ–°","ğŸ“£ äº¤æ˜“æ‰€æ›´æ–°"),
          ("ğŸ¦ åª’ä½“å¤´æ¡","ğŸ¦ åª’ä½“å¤´æ¡"),("ğŸŒ ç”Ÿæ€å™äº‹","ğŸŒ ç”Ÿæ€å™äº‹")]

def build_md(buckets, per_sec=10):
  ts=datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
  parts=[f"**æœ¬åœ°æ—¶é—´**ï¼š{ts}  \n**ç§‘åˆ›ç ”ä¹ ç¤¾ä¸“ç”¨**\n"]
  for title,key in SECTIONS:
    arr=buckets.get(key,[])
    if not arr: continue
    lines=[]; seen=set()
    for it in arr:
      if it["link"] and it["link"] in seen: continue
      seen.add(it["link"]); ttl=zhify(it["title"]); sc,ttl=score_hi(ttl)
      ts2=it["ts"] or "N/A"
      lines.append(f"- {ttl}\n  â± {ts2}  |  ğŸ”— [åŸæ–‡]({it['link']})")
      if len(lines)>=per_sec: break
    if lines: parts.append("### "+title+"\n"+"\n".join(lines)+"\n")
  if len(parts)==1: parts.append("ï¼ˆæœ¬å°æ—¶æš‚æ— æœ‰æ•ˆæ›´æ–°ï¼‰")
  parts.append("\nâ€”â€” ç§‘åˆ›ç ”ä¹ ç¤¾ä¸“ç”¨")
  return "\n".join(parts)

# ---------- ä¸»æµç¨‹ ----------
def main():
  print("ğŸš€ æŠ“å–ä¸­ â€¦")
  items=[]
  for u in (EX_RSS+MEDIA_RSS+ECO_RSS): items.extend(fetch_rss(u))
  items.extend(fetch_binance_cms(40))
  for name,base in STATUSPAGES: items.extend(fetch_statuspage(base,name))

  uniq=[]; seen=set()
  for it in items:
    lk=it.get("link","")
    if not lk or lk in seen: continue
    seen.add(lk); uniq.append(it)

  buckets={}
  for it in uniq:
    cat=classify(it); buckets.setdefault(cat,[]).append(it)
  for k in buckets: buckets[k].sort(key=lambda x:(x.get("ts","")), reverse=True)

  md=build_md(buckets, per_sec=10)

  if not PUSHPLUS_TOKEN:
    print("âš ï¸ ç¼ºå°‘ PUSHPLUS_TOKENï¼Œæ‰“å°å†…å®¹ï¼š\n", md)
    return
  tokens=[t.strip() for t in PUSHPLUS_TOKEN.split(",") if t.strip()]
  url="https://www.pushplus.plus/send"
  title="ã€å°æ—¶å¿«æŠ¥ã€‘å»é‡Â·ä¸­æ–‡åŒ–Â·ç½®é¡¶ â€” ç§‘åˆ›ç ”ä¹ ç¤¾ä¸“ç”¨"
  for tk in tokens:
    try:
      r=requests.post(url,json={"token":tk,"title":title,"content":md,"template":"markdown"},timeout=TIMEOUT)
      print("PushPlus:", tk[:6]+"***", r.status_code, r.text[:120])
    except Exception as e:
      print("PushPlus å¼‚å¸¸:", tk[:6]+"***", e)

if __name__=="__main__":
  main()